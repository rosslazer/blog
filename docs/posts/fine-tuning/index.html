<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">
    <meta name="color-scheme" content="light dark">

    
      <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests; block-all-mixed-content; default-src 'self'; child-src 'self'; font-src 'self' https://fonts.gstatic.com https://cdn.jsdelivr.net/; form-action 'self'; frame-src 'self'; img-src 'self' https://media.giphy.com; object-src 'none'; style-src 'self' 'unsafe-inline' https://fonts.googleapis.com/ https://cdn.jsdelivr.net/ https://github.githubassets.com/; script-src 'self' 'unsafe-inline' https://www.google-analytics.com https://cdn.jsdelivr.net/ https://www.googletagmanager.com/ https://gist.github.com/; prefetch-src 'self'; connect-src 'self' https://www.google-analytics.com;">

    

    <meta name="author" content="Ross Lazerowitz">
    <meta name="description" content="Using GPT to emulate my writing style">
    <meta name="keywords" content="blog,developer,personal">

    <meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://rosslazer.com/images/gpt-post.jpeg"/>

<meta name="twitter:title" content="Fine-tuning GPT3.5-turbo based on 140k slack messages"/>
<meta name="twitter:description" content="Using GPT to emulate my writing style"/>

    <meta property="og:title" content="Fine-tuning GPT3.5-turbo based on 140k slack messages" />
<meta property="og:description" content="Using GPT to emulate my writing style" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://rosslazer.com/posts/fine-tuning/" /><meta property="og:image" content="https://rosslazer.com/images/gpt-post.jpeg" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-04T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-09-04T00:00:00+00:00" />


    <title>
  Fine-tuning GPT3.5-turbo based on 140k slack messages · Ross Lazerowitz
</title>

    
      <link rel="canonical" href="https://rosslazer.com/posts/fine-tuning/">
    

    <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>

    
      
      
      <link rel="stylesheet" href="/css/coder.min.d9fddbffe6f27e69985dc5fe0471cdb0e57fbf4775714bc3d847accb08f4a1f6.css" integrity="sha256-2f3b/&#43;byfmmYXcX&#43;BHHNsOV/v0d1cUvD2Eesywj0ofY=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="/css/coder-dark.min.002ee2378e14c7a68f1f0a53d9694ed252090987c4e768023fac694a4fc5f793.css" integrity="sha256-AC7iN44Ux6aPHwpT2WlO0lIJCYfE52gCP6xpSk/F95M=" crossorigin="anonymous" media="screen" />
      
    

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    <link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

    <meta name="generator" content="Hugo 0.111.3">
  </head>

  
  
    
  
  <body class="preload-transitions colorscheme-auto">
    
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      Ross Lazerowitz
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/posts/">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/books/">Books</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/contact/">Contact me</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="https://rosslazer.com/posts/fine-tuning/">
              Fine-tuning GPT3.5-turbo based on 140k slack messages
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime='2023-09-04T00:00:00Z'>
                September 4, 2023
              </time>
            </span>
            <span class="reading-time">
              <i class="fa fa-clock-o" aria-hidden="true"></i>
              5-minute read
            </span>
          </div>
          
          
          <div class="tags">
  <i class="fa fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/tags/ai/">AI</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/gpt/">GPT</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/llms/">LLMs</a>
    </span></div>

        </div>
      </header>

      <div>
        
        <p>I recently started using the Smart Connections plugin for the Obsidian note-taking app. It generates embeddings for all of my notes and allows me to chat with them using GPT. Over the weekend I used it to generate Twitter and LinkedIn posts for a blog piece I was working on. While it produced quality content it had a lot of trouble replicating my writing style. The completions didn&rsquo;t feel like something I would write myself.</p>
<p><img src="/images/20230830212404.png" alt="Obsidian screenshot">
My first attempt to get it to write in my style was to do so with various prompts. Maybe my prompt engineering skills aren&rsquo;t good enough but I couldn&rsquo;t get it to shake the style that GPT uses. When I tried to have it extract style and tone from my previous blog pieces it didn&rsquo;t have enough data to discern between the figure of speech I normally use vs. verbiage that was specific to the piece I was writing. This got me thinking; maybe I could use the new fine-tuning API for GPT 3.5 turbo!</p>
<h2 id="fine-tuning-gpt35-turbo-based-on-140k-slack-messages">
  Fine-tuning GPT3.5-turbo based on 140k slack messages
  <a class="heading-link" href="#fine-tuning-gpt35-turbo-based-on-140k-slack-messages">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h2>
<p>Over the last four years, I&rsquo;ve amassed 140k Slack messages at Observe Inc. I downloaded a dump of all of my Slack messages and wrote a script to process it. This created a dump for every direct message or group thread. The data format looks roughly like this:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>[
</span></span><span style="display:flex;"><span>  {
</span></span><span style="display:flex;"><span>    &#34;client_msg_id&#34;: &#34;e59a1118-8164-4eb9-9623-e4114502ba30&#34;,
</span></span><span style="display:flex;"><span>    &#34;type&#34;: &#34;message&#34;,
</span></span><span style="display:flex;"><span>    &#34;text&#34;: &#34;\u003c@UMQN69N8M\u003e - How are you doing?
</span></span><span style="display:flex;"><span>    &#34;user&#34;: &#34;U01AFPBSPCKX&#34;,
</span></span><span style="display:flex;"><span>    &#34;ts&#34;: &#34;1644956438.392969&#34;,
</span></span><span style="display:flex;"><span>    &#34;blocks&#34;: [
</span></span><span style="display:flex;"><span>      {
</span></span><span style="display:flex;"><span>        &#34;type&#34;: &#34;rich_text&#34;,
</span></span><span style="display:flex;"><span>        &#34;block_id&#34;: &#34;euXh&#34;,
</span></span><span style="display:flex;"><span>        &#34;elements&#34;: [
</span></span><span style="display:flex;"><span>          {
</span></span><span style="display:flex;"><span>            &#34;type&#34;: &#34;rich_text_section&#34;,
</span></span><span style="display:flex;"><span>            &#34;elements&#34;: [
</span></span><span style="display:flex;"><span>              {
</span></span><span style="display:flex;"><span>                &#34;type&#34;: &#34;user&#34;,
</span></span><span style="display:flex;"><span>                &#34;user_id&#34;: &#34;UMQN78NMB&#34;
</span></span><span style="display:flex;"><span>              },
</span></span><span style="display:flex;"><span>              {
</span></span><span style="display:flex;"><span>                &#34;type&#34;: &#34;text&#34;,
</span></span><span style="display:flex;"><span>                &#34;text&#34;: &#34; -  How are you doing?&#34;
</span></span><span style="display:flex;"><span>              },
</span></span><span style="display:flex;"><span>              {
</span></span><span style="display:flex;"><span>                &#34;type&#34;: &#34;link&#34;,
</span></span><span style="display:flex;"><span>                &#34;url&#34;: &#34;https://foobar.com
</span></span><span style="display:flex;"><span>              }
</span></span><span style="display:flex;"><span>            ]
</span></span><span style="display:flex;"><span>          }
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    ],
</span></span><span style="display:flex;"><span>    &#34;team&#34;: &#34;T7B732R0S&#34;
</span></span><span style="display:flex;"><span>  },
</span></span><span style="display:flex;"><span>  {
</span></span><span style="display:flex;"><span>    &#34;client_msg_id&#34;: &#34;6590516f-ff2b-4268-aef2-f7bfadd0a250&#34;,
</span></span><span style="display:flex;"><span>    &#34;type&#34;: &#34;message&#34;,
</span></span><span style="display:flex;"><span>    &#34;text&#34;: &#34;I&#39;m fine and you?&#34;,
</span></span><span style="display:flex;"><span>    &#34;user&#34;: &#34;UMQN78NMB&#34;,
</span></span><span style="display:flex;"><span>    &#34;ts&#34;: &#34;1644957762.921829&#34;,
</span></span><span style="display:flex;"><span>    &#34;blocks&#34;: [
</span></span><span style="display:flex;"><span>      {
</span></span><span style="display:flex;"><span>        &#34;type&#34;: &#34;rich_text&#34;,
</span></span><span style="display:flex;"><span>        &#34;block_id&#34;: &#34;1Xntl&#34;,
</span></span><span style="display:flex;"><span>        &#34;elements&#34;: [
</span></span><span style="display:flex;"><span>          {
</span></span><span style="display:flex;"><span>            &#34;type&#34;: &#34;rich_text_section&#34;,
</span></span><span style="display:flex;"><span>            &#34;elements&#34;: [
</span></span><span style="display:flex;"><span>              {
</span></span><span style="display:flex;"><span>                &#34;type&#34;: &#34;text&#34;,
</span></span><span style="display:flex;"><span>                &#34;text&#34;: &#34;I&#39;m fine and you?&#34;
</span></span><span style="display:flex;"><span>              }
</span></span><span style="display:flex;"><span>            ]
</span></span><span style="display:flex;"><span>          }
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    ],
</span></span><span style="display:flex;"><span>    ....
</span></span><span style="display:flex;"><span>]
</span></span></code></pre></div><p>There are a few challenges with the data because there&rsquo;s no clear request/response. A user could be responding to the last message or the last series of messages. On the response side of things, every time a user types a message and presses enter, Slack treats it as a separate event. Given that this is a fun side project I opted to go with very simple (and flawed) logic to handle these cases. I even used GPT-4 to help me generate the Python script because I was feeling extra lazy. It results in some duplicates but it was good enough to get this going. You can view the script below. The goal is to shape each chat interaction into an event that looks like</p>
<p><code>{&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are Ross. He is a product manager at Observe inc. He responds to messages from his coworkers on slack and is helpful.&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: COLLATED_PRECEDING_SLACK_MESSAGES}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: COLLATED_USER_MESSAGES}]} </code></p>
<h4 id="data-prep-script">
  Data Prep Script
  <a class="heading-link" href="#data-prep-script">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h4>
<p>Curious readers can find the data munging script <a href="https://gist.github.com/rosslazer/9fc358f37f8a552fa49d47968d70a98b">here.</a>
The fine-tuning job was surprisingly easy to set up. All I had to do was upload the JSONL file and kick off a fine-tuning job. It ran for roughly 3 hours on a total of 10,399,747 tokens for a total of $83.20</p>
<h4 id="fine-tuning-job-script">
  Fine Tuning Job Script
  <a class="heading-link" href="#fine-tuning-job-script">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h4>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>new file openai.FineTuningJob.create(training_file=&#34;file-jo5xMgDc8pyuP3S6IC24440T&#34;, model=&#34;gpt-3.5-turbo&#34;)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>openai.FineTuningJob.create(training_file=&#34;file-jo5xMgDc8pyuP3S6IC24440T&#34;, model=&#34;gpt-3.5-turbo&#34;)
</span></span></code></pre></div><h2 id="where-things-get-weird">
  Where things get weird
  <a class="heading-link" href="#where-things-get-weird">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h2>
<p>Unlike the base GPT models my newly created model acts out of its mind when the temperature and frequency penalty settings are left at their defaults. Here&rsquo;s an example with a default temperature of 1.0 and a frequency penalty of 0.</p>
<p><img src="/images/20230830224259.png" alt="Model chat screenshot from OpenAI"></p>
<p>No idea what that means. Let&rsquo;s turn the temperature down and frequency penalty up.</p>
<p><img src="/images/20230830224350.png" alt="Model chat with lowre temperature"></p>
<p>Much better! As a fan of Westworld also eerily similar to something I might say. I&rsquo;m not entirely sure what&rsquo;s going on here but if you have a good reason why I need to reduce the temperature let me know. My hunch is that it&rsquo;s related to the same reason <a href="https://twitter.com/pommedeterre33/status/1671263789914677248">GPT-4 uses a mixture of different models behind the scenes</a>. I found myself turning the temperature up and down when I wanted it to be more creative vs. factual</p>
<h4 id="introspecting-myself-through-my-llm-twin">
  Introspecting myself through my LLM twin
  <a class="heading-link" href="#introspecting-myself-through-my-llm-twin">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h4>
<p>Throughout the workday, I would feed messages from my coworkers to the model. I even fed it an outline from a sales call, asked it to draw conclusions, and then asked my coworker if it was spot on.</p>
<blockquote>
<p>I had a question on this one<br>
I don’t think there are any product conclusions here<br>
but I can take a closer look<br>
I think the main conclusion is that they want to use terraform to manage access<br>
and they want to have access to restricted logs approved<br>
is there something specific you are looking for?<br>
I can read it again</p>
</blockquote>
<p>As crazy as it sounds the few hours I spent playing around with the model helped me introspect on how I use Slack and the tone I use at work. When I use Slack it&rsquo;s typically type first and think later. This shows through in the message structure the model learned. I might write something, press enter, write some more, press enter, etc. This is in contrast to email and text messages where I put a lot more thought into a message before sending it. I think it&rsquo;s mainly due to the volume of messages I have to respond to and my split brain while doing so.</p>
<p>At times I didn&rsquo;t love the tone of the completions from the model.</p>
<p><img src="/images/20230830225747.png" alt="Ross GPT being difficult"></p>
<p>It&rsquo;s not entirely fair to assume that I would write messages like this, but it&rsquo;s still an impression of how I can come off. I&rsquo;m responding to a morass of Slack messages all day (usually while trying to do something else) and that results in a lot of brevity.</p>
<h2 id="where-to-go-next">
  Where to go next
  <a class="heading-link" href="#where-to-go-next">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h2>
<p>While I had a lot of fun with this experiment I don&rsquo;t think I&rsquo;m going to revisit it for a while. Fine-tuning the model made it a lot less effective at other tasks even if it could parrot my style. It could be an interesting follow-up experiment to fine-tune the model using a non-work setting like iMessage. If I find the time I&rsquo;d like to refine my original idea of fingerprinting my writing style in a way a general model like GTP-4 can understand.</p>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

      </div>

      <footer class="footer">


  <section class="container">
    ©
    
      2022 -
    
    2023
     Ross Lazerowitz 
    ·
    
    Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
  </section>
  
</footer>

    </main>

    
      
      <script src="/js/coder.min.9cf2dbf9b6989ef8eae941ffb4231c26d1dc026bca38f1d19fdba50177d8a9ac.js" integrity="sha256-nPLb&#43;baYnvjq6UH/tCMcJtHcAmvKOPHRn9ulAXfYqaw="></script>
    

    

    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-337LD50SHT"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-337LD50SHT', { 'anonymize_ip': false });
}
</script>


    

    

    

    

    

    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-337LD50SHT"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-337LD50SHT');
</script>

  </body>

</html>
